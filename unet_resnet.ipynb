{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import six\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\n",
    "from keras.layers import Conv2D, Concatenate, MaxPooling2D\n",
    "from keras.layers import UpSampling2D, Dropout, BatchNormalization\n",
    "from tqdm import tqdm_notebook\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras.utils import conv_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.engine import InputSpec\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "from keras.engine.topology import Input\n",
    "from keras.engine.training import Model\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers.core import Activation, SpatialDropout2D\n",
    "from keras.layers.merge import concatenate,add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet_resnet_version_11.model\n",
      "Unet_resnet_version_11.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t_start = time.time()\n",
    "version = 11\n",
    "basic_name = f'Unet_resnet_version_{version}'\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "print(save_model_name)\n",
    "print(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "epochs = 75\n",
    "batch_size = 32\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"competition_data/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"competition_data/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b4dc020aa741f7a9e650eba307ea70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36826aeef34428fa7a60af5bc577911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(\"competition_data/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"masks\"] = [np.array(load_img(\"competition_data/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "def cov_to_class(val):    \n",
    "    for i in range(0, 11):\n",
    "        if val * 10 <= i :\n",
    "            return i\n",
    "        \n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "    train_df.index.values,\n",
    "    np.array(train_df.images.map(upsample).tolist()).reshape(-1,img_size_target, img_size_target, 1), \n",
    "    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    train_df.coverage.values,\n",
    "    train_df.z.values,\n",
    "    test_size = 0.05 , stratify=train_df.coverage_class, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchActivate(x):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    if activation == True:\n",
    "        x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16, batch_activate = False):\n",
    "    x = BatchActivate(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    if batch_activate:\n",
    "        x = BatchActivate(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (3, 3)\n",
    "def build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons * 1, size, activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1, True)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons * 2, size, activation=None, padding=\"same\")(pool1)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2, True)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons * 4, size, activation=None, padding=\"same\")(pool2)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4, True)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons * 8, size, activation=None, padding=\"same\")(pool3)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8, True)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, size, activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = residual_block(convm,start_neurons * 16, True)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, size, strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, size, strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n",
    "\n",
    "    # 25 -> 50\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, size, strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, size, strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n",
    "    \n",
    "    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n",
    "    output_layer =  Activation('sigmoid')(output_layer_noActi)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    batch_size = A.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch]>0, B[batch]>0       \n",
    "        intersection = np.logical_and(t, p)\n",
    "        union = np.logical_or(t, p)\n",
    "        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n",
    "        thresholds = np.arange(0.5, 1, 0.05)\n",
    "        s = []\n",
    "        for thresh in thresholds:\n",
    "            s.append(iou > thresh)\n",
    "        metric.append(np.mean(s))\n",
    "\n",
    "    return np.mean(metric)\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred > 0.3], tf.float64)\n",
    "\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred > 0.1], tf.float64)\n",
    "\n",
    "def my_iou_metric_3(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred > 0.3], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code download from: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/raghakot/keras-resnet/blob/master/resnet.py\n",
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
    "                          kernel_size=(1, 1),\n",
    "                          strides=(stride_width, stride_height),\n",
    "                          padding=\"valid\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(input)\n",
    "\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=init_strides,\n",
    "                           padding=\"same\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "                                  strides=init_strides)(input)\n",
    "\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            input = block_function(filters=filters, init_strides=init_strides,\n",
    "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "\n",
    "    return f\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, block_fn, repetitions,input_tensor):\n",
    "        _handle_dim_ordering()\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "        \n",
    "        if input_tensor is None:\n",
    "            img_input = Input(shape=input_shape)\n",
    "        else:\n",
    "            if not K.is_keras_tensor(input_tensor):\n",
    "                img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "            else:\n",
    "                img_input = input_tensor\n",
    "                \n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(img_input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        model = Model(inputs=img_input, outputs=block)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape,input_tensor):\n",
    "        return ResnetBuilder.build(input_shape, basic_block, [3, 4, 6, 3],input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UResNet34(input_shape=(128, 128, 1), classes=1, decoder_filters=16, decoder_block_type='upsampling',\n",
    "                       encoder_weights=\"imagenet\", input_tensor=None, activation='sigmoid', **kwargs):\n",
    "\n",
    "    backbone = ResnetBuilder.build_resnet_34(input_shape=input_shape,input_tensor=input_tensor)\n",
    "    \n",
    "    input_layer = backbone.input\n",
    "    output_layer = build_model(input_layer, 16,0.5)\n",
    "    model = Model(input_layer, output_layer)\n",
    "    c = optimizers.adam(lr = 0.01)\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n",
    "    model.name = 'u-resnet34'\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rnaman/opt/anaconda3/envs/kaggle_tgs/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/rnaman/opt/anaconda3/envs/kaggle_tgs/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-9-8cab8420d66a>:18: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 101, 101, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 101, 101, 16) 160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 101, 101, 16) 64          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 101, 101, 16) 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 101, 101, 16) 2320        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 101, 101, 16) 64          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 101, 101, 16) 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 101, 101, 16) 2320        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 101, 101, 16) 0           conv2d_39[0][0]                  \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 101, 101, 16) 64          add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 101, 101, 16) 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 101, 101, 16) 2320        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 101, 101, 16) 64          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 101, 101, 16) 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 101, 101, 16) 2320        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 101, 101, 16) 0           conv2d_41[0][0]                  \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 101, 101, 16) 64          add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 101, 101, 16) 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 50, 50, 16)   0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50, 50, 16)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 50, 50, 32)   4640        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 50, 50, 32)   128         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 50, 50, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 50, 50, 32)   9248        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 50, 50, 32)   128         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 50, 50, 32)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 50, 50, 32)   9248        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 50, 50, 32)   0           conv2d_44[0][0]                  \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 50, 50, 32)   128         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 50, 50, 32)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 50, 50, 32)   9248        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 50, 50, 32)   128         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 50, 50, 32)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 50, 50, 32)   9248        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 50, 50, 32)   0           conv2d_46[0][0]                  \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 50, 50, 32)   128         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 50, 50, 32)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 25, 25, 32)   0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 25, 25, 32)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 25, 25, 64)   18496       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 25, 25, 64)   256         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 25, 25, 64)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 25, 25, 64)   36928       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 25, 25, 64)   256         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 25, 25, 64)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 25, 25, 64)   36928       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 25, 25, 64)   0           conv2d_49[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 25, 25, 64)   256         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 25, 25, 64)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 25, 25, 64)   36928       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 25, 25, 64)   256         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 25, 25, 64)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 25, 25, 64)   36928       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 25, 25, 64)   0           conv2d_51[0][0]                  \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 25, 25, 64)   256         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 25, 25, 64)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 12, 12, 64)   0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 12, 12, 64)   0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 128)  73856       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 128)  512         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 128)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 128)  147584      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 128)  512         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 128)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 128)  147584      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 12, 12, 128)  0           conv2d_54[0][0]                  \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 128)  512         add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 128)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 128)  147584      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 128)  512         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 128)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 128)  147584      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 12, 12, 128)  0           conv2d_56[0][0]                  \n",
      "                                                                 add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 128)  512         add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 128)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 6, 6, 128)    0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 6, 6, 128)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 6, 6, 256)    295168      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 6, 6, 256)    1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 6, 6, 256)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 6, 6, 256)    590080      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 6, 6, 256)    1024        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 6, 6, 256)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 6, 6, 256)    590080      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 6, 6, 256)    0           conv2d_59[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 6, 6, 256)    1024        add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 6, 6, 256)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 6, 6, 256)    590080      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 6, 6, 256)    1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 6, 6, 256)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 6, 6, 256)    590080      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 6, 6, 256)    0           conv2d_61[0][0]                  \n",
      "                                                                 add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 6, 6, 256)    1024        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 6, 6, 256)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 12, 12, 128)  295040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 12, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 12, 12, 256)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 128)  295040      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 128)  512         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 128)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 128)  147584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 128)  512         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 128)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 128)  147584      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 12, 12, 128)  0           conv2d_64[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 128)  512         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 128)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 128)  147584      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 128)  512         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 128)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 128)  147584      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 12, 12, 128)  0           conv2d_66[0][0]                  \n",
      "                                                                 add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 128)  512         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 128)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 25, 25, 64)   73792       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 25, 25, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 25, 25, 128)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 25, 25, 64)   73792       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 25, 25, 64)   256         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 25, 25, 64)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 25, 25, 64)   36928       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 25, 25, 64)   256         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 25, 25, 64)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 25, 25, 64)   36928       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 25, 25, 64)   0           conv2d_69[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 25, 25, 64)   256         add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 25, 25, 64)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 25, 25, 64)   36928       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 25, 25, 64)   256         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 25, 25, 64)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 25, 25, 64)   36928       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 25, 25, 64)   0           conv2d_71[0][0]                  \n",
      "                                                                 add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 25, 25, 64)   256         add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 25, 25, 64)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 50, 50, 32)   18464       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 50, 50, 64)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 50, 50, 64)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 50, 50, 32)   18464       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 50, 50, 32)   128         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 50, 50, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 50, 50, 32)   9248        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 50, 50, 32)   128         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 50, 50, 32)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 50, 50, 32)   9248        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 50, 50, 32)   0           conv2d_74[0][0]                  \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 50, 50, 32)   128         add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 50, 50, 32)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 50, 50, 32)   9248        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 50, 50, 32)   128         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 50, 50, 32)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 50, 50, 32)   9248        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 50, 50, 32)   0           conv2d_76[0][0]                  \n",
      "                                                                 add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 50, 50, 32)   128         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 50, 50, 32)   0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 101, 101, 16) 4624        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 101, 101, 32) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 101, 101, 32) 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 101, 101, 16) 4624        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 101, 101, 16) 64          conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 101, 101, 16) 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 101, 101, 16) 2320        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 101, 101, 16) 64          conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 101, 101, 16) 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 101, 101, 16) 2320        activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 101, 101, 16) 0           conv2d_79[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 101, 101, 16) 64          add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 101, 101, 16) 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 101, 101, 16) 2320        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 101, 101, 16) 64          conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 101, 101, 16) 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 101, 101, 16) 2320        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 101, 101, 16) 0           conv2d_81[0][0]                  \n",
      "                                                                 add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 101, 101, 16) 64          add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 101, 101, 16) 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 101, 101, 1)  17          activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 101, 101, 1)  0           conv2d_82[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,119,857\n",
      "Trainable params: 5,112,497\n",
      "Non-trainable params: 7,360\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = UResNet34( input_shape = (1,img_size_target,img_size_target))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rnaman/opt/anaconda3/envs/kaggle_tgs/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7600 samples, validate on 200 samples\n",
      "Epoch 1/75\n",
      "7600/7600 [==============================] - 1507s 198ms/step - loss: 0.4603 - my_iou_metric: 0.1392 - val_loss: 0.4806 - val_my_iou_metric: 0.0925\n",
      "\n",
      "Epoch 00001: my_iou_metric improved from -inf to 0.13920, saving model to Unet_resnet_version_11.model\n",
      "Epoch 2/75\n",
      "7600/7600 [==============================] - 1496s 197ms/step - loss: 0.3592 - my_iou_metric: 0.2214 - val_loss: 0.4368 - val_my_iou_metric: 0.2665\n",
      "\n",
      "Epoch 00002: my_iou_metric improved from 0.13920 to 0.22141, saving model to Unet_resnet_version_11.model\n",
      "Epoch 3/75\n",
      "7600/7600 [==============================] - 1428s 188ms/step - loss: 0.3242 - my_iou_metric: 0.3044 - val_loss: 0.4106 - val_my_iou_metric: 0.1415\n",
      "\n",
      "Epoch 00003: my_iou_metric improved from 0.22141 to 0.30441, saving model to Unet_resnet_version_11.model\n",
      "Epoch 4/75\n",
      "7600/7600 [==============================] - 1413s 186ms/step - loss: 0.2847 - my_iou_metric: 0.3982 - val_loss: 0.8039 - val_my_iou_metric: 0.2525\n",
      "\n",
      "Epoch 00004: my_iou_metric improved from 0.30441 to 0.39824, saving model to Unet_resnet_version_11.model\n",
      "Epoch 5/75\n",
      "7600/7600 [==============================] - 1409s 185ms/step - loss: 0.2582 - my_iou_metric: 0.4599 - val_loss: 0.4419 - val_my_iou_metric: 0.4930\n",
      "\n",
      "Epoch 00005: my_iou_metric improved from 0.39824 to 0.45989, saving model to Unet_resnet_version_11.model\n",
      "Epoch 6/75\n",
      "7600/7600 [==============================] - 1386s 182ms/step - loss: 0.2425 - my_iou_metric: 0.4973 - val_loss: 0.8503 - val_my_iou_metric: 0.2790\n",
      "\n",
      "Epoch 00006: my_iou_metric improved from 0.45989 to 0.49729, saving model to Unet_resnet_version_11.model\n",
      "Epoch 7/75\n",
      "7600/7600 [==============================] - 1377s 181ms/step - loss: 0.2241 - my_iou_metric: 0.5204 - val_loss: 0.5364 - val_my_iou_metric: 0.1280\n",
      "\n",
      "Epoch 00007: my_iou_metric improved from 0.49729 to 0.52039, saving model to Unet_resnet_version_11.model\n",
      "Epoch 8/75\n",
      "7600/7600 [==============================] - 1369s 180ms/step - loss: 0.2192 - my_iou_metric: 0.5335 - val_loss: 0.3405 - val_my_iou_metric: 0.5275\n",
      "\n",
      "Epoch 00008: my_iou_metric improved from 0.52039 to 0.53353, saving model to Unet_resnet_version_11.model\n",
      "Epoch 9/75\n",
      "7600/7600 [==============================] - 1499s 197ms/step - loss: 0.2016 - my_iou_metric: 0.5619 - val_loss: 0.1990 - val_my_iou_metric: 0.5275\n",
      "\n",
      "Epoch 00009: my_iou_metric improved from 0.53353 to 0.56193, saving model to Unet_resnet_version_11.model\n",
      "Epoch 10/75\n",
      "7600/7600 [==============================] - 1393s 183ms/step - loss: 0.1990 - my_iou_metric: 0.5680 - val_loss: 0.2162 - val_my_iou_metric: 0.6020\n",
      "\n",
      "Epoch 00010: my_iou_metric improved from 0.56193 to 0.56799, saving model to Unet_resnet_version_11.model\n",
      "Epoch 11/75\n",
      "7600/7600 [==============================] - 1247s 164ms/step - loss: 0.1928 - my_iou_metric: 0.5794 - val_loss: 0.2197 - val_my_iou_metric: 0.6735\n",
      "\n",
      "Epoch 00011: my_iou_metric improved from 0.56799 to 0.57941, saving model to Unet_resnet_version_11.model\n",
      "Epoch 12/75\n",
      "7600/7600 [==============================] - 1250s 164ms/step - loss: 0.1862 - my_iou_metric: 0.5841 - val_loss: 0.2166 - val_my_iou_metric: 0.6445\n",
      "\n",
      "Epoch 00012: my_iou_metric improved from 0.57941 to 0.58409, saving model to Unet_resnet_version_11.model\n",
      "Epoch 13/75\n",
      "7600/7600 [==============================] - 1291s 170ms/step - loss: 0.1804 - my_iou_metric: 0.5959 - val_loss: 0.1833 - val_my_iou_metric: 0.5260\n",
      "\n",
      "Epoch 00013: my_iou_metric improved from 0.58409 to 0.59595, saving model to Unet_resnet_version_11.model\n",
      "Epoch 14/75\n",
      "7600/7600 [==============================] - 1477s 194ms/step - loss: 0.1733 - my_iou_metric: 0.6046 - val_loss: 0.1550 - val_my_iou_metric: 0.6630\n",
      "\n",
      "Epoch 00014: my_iou_metric improved from 0.59595 to 0.60455, saving model to Unet_resnet_version_11.model\n",
      "Epoch 15/75\n",
      "7600/7600 [==============================] - 1458s 192ms/step - loss: 0.1661 - my_iou_metric: 0.6233 - val_loss: 0.1611 - val_my_iou_metric: 0.7175\n",
      "\n",
      "Epoch 00015: my_iou_metric improved from 0.60455 to 0.62334, saving model to Unet_resnet_version_11.model\n",
      "Epoch 16/75\n",
      "7600/7600 [==============================] - 1301s 171ms/step - loss: 0.1693 - my_iou_metric: 0.6177 - val_loss: 0.1789 - val_my_iou_metric: 0.6100\n",
      "\n",
      "Epoch 00016: my_iou_metric did not improve from 0.62334\n",
      "Epoch 17/75\n",
      "7600/7600 [==============================] - 1197s 157ms/step - loss: 0.1635 - my_iou_metric: 0.6233 - val_loss: 0.4541 - val_my_iou_metric: 0.4535\n",
      "\n",
      "Epoch 00017: my_iou_metric did not improve from 0.62334\n",
      "Epoch 18/75\n",
      "7600/7600 [==============================] - 1199s 158ms/step - loss: 0.1643 - my_iou_metric: 0.6202 - val_loss: 0.1576 - val_my_iou_metric: 0.7205\n",
      "\n",
      "Epoch 00018: my_iou_metric did not improve from 0.62334\n",
      "Epoch 19/75\n",
      "7600/7600 [==============================] - 1201s 158ms/step - loss: 0.1594 - my_iou_metric: 0.6307 - val_loss: 0.1684 - val_my_iou_metric: 0.5465\n",
      "\n",
      "Epoch 00019: my_iou_metric improved from 0.62334 to 0.63072, saving model to Unet_resnet_version_11.model\n",
      "Epoch 20/75\n",
      "7600/7600 [==============================] - 1194s 157ms/step - loss: 0.1522 - my_iou_metric: 0.6388 - val_loss: 0.1300 - val_my_iou_metric: 0.6740\n",
      "\n",
      "Epoch 00020: my_iou_metric improved from 0.63072 to 0.63878, saving model to Unet_resnet_version_11.model\n",
      "Epoch 21/75\n",
      "7600/7600 [==============================] - 1189s 156ms/step - loss: 0.1508 - my_iou_metric: 0.6431 - val_loss: 0.1973 - val_my_iou_metric: 0.4875\n",
      "\n",
      "Epoch 00021: my_iou_metric improved from 0.63878 to 0.64313, saving model to Unet_resnet_version_11.model\n",
      "Epoch 22/75\n",
      "7600/7600 [==============================] - 1188s 156ms/step - loss: 0.1565 - my_iou_metric: 0.6332 - val_loss: 0.7312 - val_my_iou_metric: 0.2465\n",
      "\n",
      "Epoch 00022: my_iou_metric did not improve from 0.64313\n",
      "Epoch 23/75\n",
      "7600/7600 [==============================] - 1188s 156ms/step - loss: 0.1447 - my_iou_metric: 0.6557 - val_loss: 0.1603 - val_my_iou_metric: 0.6390\n",
      "\n",
      "Epoch 00023: my_iou_metric improved from 0.64313 to 0.65566, saving model to Unet_resnet_version_11.model\n",
      "Epoch 24/75\n",
      "7600/7600 [==============================] - 1186s 156ms/step - loss: 0.1457 - my_iou_metric: 0.6516 - val_loss: 0.2185 - val_my_iou_metric: 0.7140\n",
      "\n",
      "Epoch 00024: my_iou_metric did not improve from 0.65566\n",
      "Epoch 25/75\n",
      "7600/7600 [==============================] - 1184s 156ms/step - loss: 0.1396 - my_iou_metric: 0.6629 - val_loss: 0.1699 - val_my_iou_metric: 0.7325\n",
      "\n",
      "Epoch 00025: my_iou_metric improved from 0.65566 to 0.66292, saving model to Unet_resnet_version_11.model\n",
      "Epoch 26/75\n",
      "7600/7600 [==============================] - 1183s 156ms/step - loss: 0.1410 - my_iou_metric: 0.6658 - val_loss: 0.1569 - val_my_iou_metric: 0.6915\n",
      "\n",
      "Epoch 00026: my_iou_metric improved from 0.66292 to 0.66584, saving model to Unet_resnet_version_11.model\n",
      "Epoch 27/75\n",
      "7600/7600 [==============================] - 1183s 156ms/step - loss: 0.1400 - my_iou_metric: 0.6594 - val_loss: 0.2910 - val_my_iou_metric: 0.5015\n",
      "\n",
      "Epoch 00027: my_iou_metric did not improve from 0.66584\n",
      "Epoch 28/75\n",
      "7600/7600 [==============================] - 1183s 156ms/step - loss: 0.1362 - my_iou_metric: 0.6639 - val_loss: 0.1192 - val_my_iou_metric: 0.6865\n",
      "\n",
      "Epoch 00028: my_iou_metric did not improve from 0.66584\n",
      "Epoch 29/75\n",
      "7600/7600 [==============================] - 1183s 156ms/step - loss: 0.1335 - my_iou_metric: 0.6696 - val_loss: 0.1312 - val_my_iou_metric: 0.7150\n",
      "\n",
      "Epoch 00029: my_iou_metric improved from 0.66584 to 0.66962, saving model to Unet_resnet_version_11.model\n",
      "Epoch 30/75\n",
      "7600/7600 [==============================] - 1183s 156ms/step - loss: 0.1323 - my_iou_metric: 0.6738 - val_loss: 0.2979 - val_my_iou_metric: 0.5680\n",
      "\n",
      "Epoch 00030: my_iou_metric improved from 0.66962 to 0.67384, saving model to Unet_resnet_version_11.model\n",
      "Epoch 31/75\n",
      "7600/7600 [==============================] - 1185s 156ms/step - loss: 0.1310 - my_iou_metric: 0.6847 - val_loss: 0.1952 - val_my_iou_metric: 0.6090\n",
      "\n",
      "Epoch 00031: my_iou_metric improved from 0.67384 to 0.68472, saving model to Unet_resnet_version_11.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/75\n",
      "7600/7600 [==============================] - 1184s 156ms/step - loss: 0.1282 - my_iou_metric: 0.6788 - val_loss: 0.1809 - val_my_iou_metric: 0.6770\n",
      "\n",
      "Epoch 00032: my_iou_metric did not improve from 0.68472\n",
      "Epoch 33/75\n",
      "7600/7600 [==============================] - 1184s 156ms/step - loss: 0.1243 - my_iou_metric: 0.6875 - val_loss: 0.2611 - val_my_iou_metric: 0.6705\n",
      "\n",
      "Epoch 00033: my_iou_metric improved from 0.68472 to 0.68753, saving model to Unet_resnet_version_11.model\n",
      "Epoch 34/75\n",
      "7600/7600 [==============================] - 1185s 156ms/step - loss: 0.1303 - my_iou_metric: 0.6762 - val_loss: 0.1787 - val_my_iou_metric: 0.7170\n",
      "\n",
      "Epoch 00034: my_iou_metric did not improve from 0.68753\n",
      "Epoch 35/75\n",
      "7600/7600 [==============================] - 1185s 156ms/step - loss: 0.1231 - my_iou_metric: 0.6837 - val_loss: 0.1330 - val_my_iou_metric: 0.7475\n",
      "\n",
      "Epoch 00035: my_iou_metric did not improve from 0.68753\n",
      "Epoch 36/75\n",
      "7600/7600 [==============================] - 1185s 156ms/step - loss: 0.1209 - my_iou_metric: 0.6849 - val_loss: 0.1477 - val_my_iou_metric: 0.6880\n",
      "\n",
      "Epoch 00036: my_iou_metric did not improve from 0.68753\n",
      "Epoch 37/75\n",
      "7600/7600 [==============================] - 1185s 156ms/step - loss: 0.1231 - my_iou_metric: 0.6880 - val_loss: 0.1188 - val_my_iou_metric: 0.7090\n",
      "\n",
      "Epoch 00037: my_iou_metric improved from 0.68753 to 0.68804, saving model to Unet_resnet_version_11.model\n",
      "Epoch 38/75\n",
      "7600/7600 [==============================] - 1185s 156ms/step - loss: 0.1161 - my_iou_metric: 0.7011 - val_loss: 0.1301 - val_my_iou_metric: 0.7065\n",
      "\n",
      "Epoch 00038: my_iou_metric improved from 0.68804 to 0.70108, saving model to Unet_resnet_version_11.model\n",
      "Epoch 39/75\n",
      "7600/7600 [==============================] - 1185s 156ms/step - loss: 0.1156 - my_iou_metric: 0.7026 - val_loss: 0.1259 - val_my_iou_metric: 0.7575\n",
      "\n",
      "Epoch 00039: my_iou_metric improved from 0.70108 to 0.70261, saving model to Unet_resnet_version_11.model\n",
      "Epoch 40/75\n",
      "7600/7600 [==============================] - 1186s 156ms/step - loss: 0.1156 - my_iou_metric: 0.7043 - val_loss: 0.1581 - val_my_iou_metric: 0.6840\n",
      "\n",
      "Epoch 00040: my_iou_metric improved from 0.70261 to 0.70430, saving model to Unet_resnet_version_11.model\n",
      "Epoch 41/75\n",
      "7600/7600 [==============================] - 1186s 156ms/step - loss: 0.1122 - my_iou_metric: 0.7121 - val_loss: 0.1339 - val_my_iou_metric: 0.7825\n",
      "\n",
      "Epoch 00041: my_iou_metric improved from 0.70430 to 0.71209, saving model to Unet_resnet_version_11.model\n",
      "Epoch 42/75\n",
      "7600/7600 [==============================] - 1185s 156ms/step - loss: 0.1125 - my_iou_metric: 0.7121 - val_loss: 0.2111 - val_my_iou_metric: 0.6785\n",
      "\n",
      "Epoch 00042: my_iou_metric did not improve from 0.71209\n",
      "Epoch 43/75\n",
      "7600/7600 [==============================] - 1185s 156ms/step - loss: 0.1118 - my_iou_metric: 0.7045 - val_loss: 0.3003 - val_my_iou_metric: 0.6915\n",
      "\n",
      "Epoch 00043: my_iou_metric did not improve from 0.71209\n",
      "Epoch 44/75\n",
      "7600/7600 [==============================] - 1185s 156ms/step - loss: 0.1129 - my_iou_metric: 0.7096 - val_loss: 0.1529 - val_my_iou_metric: 0.7765\n",
      "\n",
      "Epoch 00044: my_iou_metric did not improve from 0.71209\n",
      "Epoch 45/75\n",
      "7600/7600 [==============================] - 1194s 157ms/step - loss: 0.1104 - my_iou_metric: 0.7097 - val_loss: 0.1207 - val_my_iou_metric: 0.7585\n",
      "\n",
      "Epoch 00045: my_iou_metric did not improve from 0.71209\n",
      "Epoch 46/75\n",
      "7600/7600 [==============================] - 1232s 162ms/step - loss: 0.1069 - my_iou_metric: 0.7100 - val_loss: 0.1223 - val_my_iou_metric: 0.8080\n",
      "\n",
      "Epoch 00046: my_iou_metric did not improve from 0.71209\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 47/75\n",
      "7600/7600 [==============================] - 1319s 174ms/step - loss: 0.0934 - my_iou_metric: 0.7393 - val_loss: 0.1282 - val_my_iou_metric: 0.7795\n",
      "\n",
      "Epoch 00047: my_iou_metric improved from 0.71209 to 0.73932, saving model to Unet_resnet_version_11.model\n",
      "Epoch 48/75\n",
      "7600/7600 [==============================] - 1256s 165ms/step - loss: 0.0943 - my_iou_metric: 0.7304 - val_loss: 0.1134 - val_my_iou_metric: 0.7735\n",
      "\n",
      "Epoch 00048: my_iou_metric did not improve from 0.73932\n",
      "Epoch 49/75\n",
      "7600/7600 [==============================] - 1285s 169ms/step - loss: 0.0898 - my_iou_metric: 0.7404 - val_loss: 0.1183 - val_my_iou_metric: 0.7090\n",
      "\n",
      "Epoch 00049: my_iou_metric improved from 0.73932 to 0.74036, saving model to Unet_resnet_version_11.model\n",
      "Epoch 50/75\n",
      "7600/7600 [==============================] - 1309s 172ms/step - loss: 0.0866 - my_iou_metric: 0.7437 - val_loss: 0.1262 - val_my_iou_metric: 0.7525\n",
      "\n",
      "Epoch 00050: my_iou_metric improved from 0.74036 to 0.74370, saving model to Unet_resnet_version_11.model\n",
      "Epoch 51/75\n",
      "7600/7600 [==============================] - 1289s 170ms/step - loss: 0.0889 - my_iou_metric: 0.7386 - val_loss: 0.1493 - val_my_iou_metric: 0.7830\n",
      "\n",
      "Epoch 00051: my_iou_metric did not improve from 0.74370\n",
      "Epoch 52/75\n",
      "7600/7600 [==============================] - 1284s 169ms/step - loss: 0.0873 - my_iou_metric: 0.7405 - val_loss: 0.1502 - val_my_iou_metric: 0.7810\n",
      "\n",
      "Epoch 00052: my_iou_metric did not improve from 0.74370\n",
      "Epoch 53/75\n",
      "7600/7600 [==============================] - 1292s 170ms/step - loss: 0.0878 - my_iou_metric: 0.7411 - val_loss: 0.1268 - val_my_iou_metric: 0.8025\n",
      "\n",
      "Epoch 00053: my_iou_metric did not improve from 0.74370\n",
      "Epoch 54/75\n",
      "7600/7600 [==============================] - 1364s 179ms/step - loss: 0.0828 - my_iou_metric: 0.7471 - val_loss: 0.1509 - val_my_iou_metric: 0.7465\n",
      "\n",
      "Epoch 00054: my_iou_metric improved from 0.74370 to 0.74708, saving model to Unet_resnet_version_11.model\n",
      "Epoch 55/75\n",
      "7600/7600 [==============================] - 1442s 190ms/step - loss: 0.0829 - my_iou_metric: 0.7520 - val_loss: 0.2176 - val_my_iou_metric: 0.7130\n",
      "\n",
      "Epoch 00055: my_iou_metric improved from 0.74708 to 0.75203, saving model to Unet_resnet_version_11.model\n",
      "Epoch 56/75\n",
      "7600/7600 [==============================] - 1355s 178ms/step - loss: 0.0828 - my_iou_metric: 0.7512 - val_loss: 0.0858 - val_my_iou_metric: 0.7805\n",
      "\n",
      "Epoch 00056: my_iou_metric did not improve from 0.75203\n",
      "Epoch 57/75\n",
      "7600/7600 [==============================] - 1338s 176ms/step - loss: 0.0833 - my_iou_metric: 0.7463 - val_loss: 0.1179 - val_my_iou_metric: 0.7390\n",
      "\n",
      "Epoch 00057: my_iou_metric did not improve from 0.75203\n",
      "Epoch 58/75\n",
      "7600/7600 [==============================] - 1395s 184ms/step - loss: 0.0816 - my_iou_metric: 0.7504 - val_loss: 0.0992 - val_my_iou_metric: 0.7785\n",
      "\n",
      "Epoch 00058: my_iou_metric did not improve from 0.75203\n",
      "Epoch 59/75\n",
      "7600/7600 [==============================] - 1318s 173ms/step - loss: 0.0803 - my_iou_metric: 0.7517 - val_loss: 0.1148 - val_my_iou_metric: 0.7685\n",
      "\n",
      "Epoch 00059: my_iou_metric did not improve from 0.75203\n",
      "Epoch 60/75\n",
      "7600/7600 [==============================] - 1287s 169ms/step - loss: 0.0850 - my_iou_metric: 0.7506 - val_loss: 0.1219 - val_my_iou_metric: 0.7875\n",
      "\n",
      "Epoch 00060: my_iou_metric did not improve from 0.75203\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 61/75\n",
      "7600/7600 [==============================] - 1255s 165ms/step - loss: 0.0725 - my_iou_metric: 0.7660 - val_loss: 0.1176 - val_my_iou_metric: 0.7855\n",
      "\n",
      "Epoch 00061: my_iou_metric improved from 0.75203 to 0.76599, saving model to Unet_resnet_version_11.model\n",
      "Epoch 62/75\n",
      "7600/7600 [==============================] - 1248s 164ms/step - loss: 0.0707 - my_iou_metric: 0.7642 - val_loss: 0.1091 - val_my_iou_metric: 0.8145\n",
      "\n",
      "Epoch 00062: my_iou_metric did not improve from 0.76599\n",
      "Epoch 63/75\n",
      "7600/7600 [==============================] - 1233s 162ms/step - loss: 0.0696 - my_iou_metric: 0.7656 - val_loss: 0.1454 - val_my_iou_metric: 0.7995\n",
      "\n",
      "Epoch 00063: my_iou_metric did not improve from 0.76599\n",
      "Epoch 64/75\n",
      "7600/7600 [==============================] - 1351s 178ms/step - loss: 0.0654 - my_iou_metric: 0.7717 - val_loss: 0.0918 - val_my_iou_metric: 0.7940\n",
      "\n",
      "Epoch 00064: my_iou_metric improved from 0.76599 to 0.77171, saving model to Unet_resnet_version_11.model\n",
      "Epoch 65/75\n",
      "7600/7600 [==============================] - 1541s 203ms/step - loss: 0.0684 - my_iou_metric: 0.7702 - val_loss: 0.1167 - val_my_iou_metric: 0.8085\n",
      "\n",
      "Epoch 00065: my_iou_metric did not improve from 0.77171\n",
      "Epoch 66/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7600/7600 [==============================] - 1367s 180ms/step - loss: 0.0664 - my_iou_metric: 0.7672 - val_loss: 0.1332 - val_my_iou_metric: 0.8035\n",
      "\n",
      "Epoch 00066: my_iou_metric did not improve from 0.77171\n",
      "Epoch 67/75\n",
      "7600/7600 [==============================] - 1291s 170ms/step - loss: 0.0648 - my_iou_metric: 0.7708 - val_loss: 0.1371 - val_my_iou_metric: 0.7975\n",
      "\n",
      "Epoch 00067: my_iou_metric did not improve from 0.77171\n",
      "Epoch 68/75\n",
      "7600/7600 [==============================] - 1304s 172ms/step - loss: 0.0642 - my_iou_metric: 0.7744 - val_loss: 0.1333 - val_my_iou_metric: 0.8125\n",
      "\n",
      "Epoch 00068: my_iou_metric improved from 0.77171 to 0.77442, saving model to Unet_resnet_version_11.model\n",
      "Epoch 69/75\n",
      "7600/7600 [==============================] - 1399s 184ms/step - loss: 0.0634 - my_iou_metric: 0.7708 - val_loss: 0.1411 - val_my_iou_metric: 0.7780\n",
      "\n",
      "Epoch 00069: my_iou_metric did not improve from 0.77442\n",
      "Epoch 70/75\n",
      "7600/7600 [==============================] - 1372s 180ms/step - loss: 0.0639 - my_iou_metric: 0.7762 - val_loss: 0.1348 - val_my_iou_metric: 0.7885\n",
      "\n",
      "Epoch 00070: my_iou_metric improved from 0.77442 to 0.77620, saving model to Unet_resnet_version_11.model\n",
      "Epoch 71/75\n",
      "7600/7600 [==============================] - 1319s 174ms/step - loss: 0.0627 - my_iou_metric: 0.7707 - val_loss: 0.1104 - val_my_iou_metric: 0.8085\n",
      "\n",
      "Epoch 00071: my_iou_metric did not improve from 0.77620\n",
      "Epoch 72/75\n",
      "7600/7600 [==============================] - 1307s 172ms/step - loss: 0.0622 - my_iou_metric: 0.7751 - val_loss: 0.1064 - val_my_iou_metric: 0.7535\n",
      "\n",
      "Epoch 00072: my_iou_metric did not improve from 0.77620\n",
      "Epoch 73/75\n",
      "7600/7600 [==============================] - 1406s 185ms/step - loss: 0.0617 - my_iou_metric: 0.7743 - val_loss: 0.1132 - val_my_iou_metric: 0.7870\n",
      "\n",
      "Epoch 00073: my_iou_metric did not improve from 0.77620\n",
      "Epoch 74/75\n",
      "7600/7600 [==============================] - 1341s 176ms/step - loss: 0.0591 - my_iou_metric: 0.7802 - val_loss: 0.1214 - val_my_iou_metric: 0.7745\n",
      "\n",
      "Epoch 00074: my_iou_metric improved from 0.77620 to 0.78022, saving model to Unet_resnet_version_11.model\n",
      "Epoch 75/75\n",
      "7600/7600 [==============================] - 1319s 174ms/step - loss: 0.0581 - my_iou_metric: 0.7821 - val_loss: 0.0928 - val_my_iou_metric: 0.8020\n",
      "\n",
      "Epoch 00075: my_iou_metric improved from 0.78022 to 0.78209, saving model to Unet_resnet_version_11.model\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='my_iou_metric', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='my_iou_metric', mode = 'max',factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n",
    "\n",
    "history = model1.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[ model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric})\n",
    "# remove layter activation layer and use losvasz loss\n",
    "input_x = model1.layers[0].input\n",
    "\n",
    "output_layer = model1.layers[-1].input\n",
    "model = Model(input_x, output_layer)\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "\n",
    "# lovasz_loss need input range (-+), so cancel the last \"sigmoid\" activation  \n",
    "# Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
    "model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7600 samples, validate on 200 samples\n",
      "Epoch 1/75\n",
      "7600/7600 [==============================] - 1284s 169ms/step - loss: 0.4103 - my_iou_metric_2: 0.7929 - val_loss: 0.3924 - val_my_iou_metric_2: 0.7865\n",
      "\n",
      "Epoch 00001: val_my_iou_metric_2 improved from -inf to 0.78650, saving model to Unet_resnet_version_11.model\n",
      "Epoch 2/75\n",
      "7600/7600 [==============================] - 1305s 172ms/step - loss: 0.3752 - my_iou_metric_2: 0.7920 - val_loss: 0.5701 - val_my_iou_metric_2: 0.6925\n",
      "\n",
      "Epoch 00002: val_my_iou_metric_2 did not improve from 0.78650\n",
      "Epoch 3/75\n",
      "7600/7600 [==============================] - 1303s 171ms/step - loss: 0.3712 - my_iou_metric_2: 0.7892 - val_loss: 0.3840 - val_my_iou_metric_2: 0.7870\n",
      "\n",
      "Epoch 00003: val_my_iou_metric_2 improved from 0.78650 to 0.78700, saving model to Unet_resnet_version_11.model\n",
      "Epoch 4/75\n",
      "7600/7600 [==============================] - 1293s 170ms/step - loss: 0.3686 - my_iou_metric_2: 0.7873 - val_loss: 0.3863 - val_my_iou_metric_2: 0.7940\n",
      "\n",
      "Epoch 00004: val_my_iou_metric_2 improved from 0.78700 to 0.79400, saving model to Unet_resnet_version_11.model\n",
      "Epoch 5/75\n",
      "7600/7600 [==============================] - 1287s 169ms/step - loss: 0.3816 - my_iou_metric_2: 0.7806 - val_loss: 0.3333 - val_my_iou_metric_2: 0.8080\n",
      "\n",
      "Epoch 00005: val_my_iou_metric_2 improved from 0.79400 to 0.80800, saving model to Unet_resnet_version_11.model\n",
      "Epoch 6/75\n",
      "7600/7600 [==============================] - 1272s 167ms/step - loss: 0.3774 - my_iou_metric_2: 0.7815 - val_loss: 0.4670 - val_my_iou_metric_2: 0.7535\n",
      "\n",
      "Epoch 00006: val_my_iou_metric_2 did not improve from 0.80800\n",
      "Epoch 7/75\n",
      "7600/7600 [==============================] - 1268s 167ms/step - loss: 0.3745 - my_iou_metric_2: 0.7822 - val_loss: 0.3985 - val_my_iou_metric_2: 0.7670\n",
      "\n",
      "Epoch 00007: val_my_iou_metric_2 did not improve from 0.80800\n",
      "Epoch 8/75\n",
      "7600/7600 [==============================] - 1277s 168ms/step - loss: 0.3852 - my_iou_metric_2: 0.7783 - val_loss: 0.5035 - val_my_iou_metric_2: 0.7215\n",
      "\n",
      "Epoch 00008: val_my_iou_metric_2 did not improve from 0.80800\n",
      "Epoch 9/75\n",
      "7600/7600 [==============================] - 1214s 160ms/step - loss: 0.3625 - my_iou_metric_2: 0.7886 - val_loss: 0.4847 - val_my_iou_metric_2: 0.7200\n",
      "\n",
      "Epoch 00009: val_my_iou_metric_2 did not improve from 0.80800\n",
      "Epoch 10/75\n",
      "7600/7600 [==============================] - 1218s 160ms/step - loss: 0.3733 - my_iou_metric_2: 0.7848 - val_loss: 0.3712 - val_my_iou_metric_2: 0.7855\n",
      "\n",
      "Epoch 00010: val_my_iou_metric_2 did not improve from 0.80800\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 11/75\n",
      "7600/7600 [==============================] - 1231s 162ms/step - loss: 0.3331 - my_iou_metric_2: 0.8041 - val_loss: 0.3609 - val_my_iou_metric_2: 0.7965\n",
      "\n",
      "Epoch 00011: val_my_iou_metric_2 did not improve from 0.80800\n",
      "Epoch 12/75\n",
      "7600/7600 [==============================] - 1231s 162ms/step - loss: 0.3208 - my_iou_metric_2: 0.8097 - val_loss: 0.3269 - val_my_iou_metric_2: 0.8045\n",
      "\n",
      "Epoch 00012: val_my_iou_metric_2 did not improve from 0.80800\n",
      "Epoch 13/75\n",
      "7600/7600 [==============================] - 1227s 161ms/step - loss: 0.3189 - my_iou_metric_2: 0.8111 - val_loss: 0.4004 - val_my_iou_metric_2: 0.7830\n",
      "\n",
      "Epoch 00013: val_my_iou_metric_2 did not improve from 0.80800\n",
      "Epoch 14/75\n",
      "7600/7600 [==============================] - 1225s 161ms/step - loss: 0.3254 - my_iou_metric_2: 0.8083 - val_loss: 0.3223 - val_my_iou_metric_2: 0.8165\n",
      "\n",
      "Epoch 00014: val_my_iou_metric_2 improved from 0.80800 to 0.81650, saving model to Unet_resnet_version_11.model\n",
      "Epoch 15/75\n",
      "7600/7600 [==============================] - 1226s 161ms/step - loss: 0.3132 - my_iou_metric_2: 0.8150 - val_loss: 0.3486 - val_my_iou_metric_2: 0.7990\n",
      "\n",
      "Epoch 00015: val_my_iou_metric_2 did not improve from 0.81650\n",
      "Epoch 16/75\n",
      "7600/7600 [==============================] - 1228s 162ms/step - loss: 0.3122 - my_iou_metric_2: 0.8135 - val_loss: 0.3492 - val_my_iou_metric_2: 0.8065\n",
      "\n",
      "Epoch 00016: val_my_iou_metric_2 did not improve from 0.81650\n",
      "Epoch 17/75\n",
      "7600/7600 [==============================] - 1225s 161ms/step - loss: 0.3153 - my_iou_metric_2: 0.8110 - val_loss: 0.3277 - val_my_iou_metric_2: 0.8170\n",
      "\n",
      "Epoch 00017: val_my_iou_metric_2 improved from 0.81650 to 0.81700, saving model to Unet_resnet_version_11.model\n",
      "Epoch 18/75\n",
      "7600/7600 [==============================] - 1222s 161ms/step - loss: 0.3129 - my_iou_metric_2: 0.8135 - val_loss: 0.3351 - val_my_iou_metric_2: 0.8125\n",
      "\n",
      "Epoch 00018: val_my_iou_metric_2 did not improve from 0.81700\n",
      "Epoch 19/75\n",
      "7600/7600 [==============================] - 1219s 160ms/step - loss: 0.3173 - my_iou_metric_2: 0.8105 - val_loss: 0.3303 - val_my_iou_metric_2: 0.8170\n",
      "\n",
      "Epoch 00019: val_my_iou_metric_2 did not improve from 0.81700\n",
      "Epoch 20/75\n",
      "7600/7600 [==============================] - 1218s 160ms/step - loss: 0.3122 - my_iou_metric_2: 0.8125 - val_loss: 0.3416 - val_my_iou_metric_2: 0.8115\n",
      "\n",
      "Epoch 00020: val_my_iou_metric_2 did not improve from 0.81700\n",
      "Epoch 21/75\n",
      "7600/7600 [==============================] - 1219s 160ms/step - loss: 0.3135 - my_iou_metric_2: 0.8137 - val_loss: 0.3196 - val_my_iou_metric_2: 0.8195\n",
      "\n",
      "Epoch 00021: val_my_iou_metric_2 improved from 0.81700 to 0.81950, saving model to Unet_resnet_version_11.model\n",
      "Epoch 22/75\n",
      "7600/7600 [==============================] - 1217s 160ms/step - loss: 0.3068 - my_iou_metric_2: 0.8167 - val_loss: 0.3338 - val_my_iou_metric_2: 0.8095\n",
      "\n",
      "Epoch 00022: val_my_iou_metric_2 did not improve from 0.81950\n",
      "Epoch 23/75\n",
      "7600/7600 [==============================] - 1217s 160ms/step - loss: 0.3015 - my_iou_metric_2: 0.8186 - val_loss: 0.3331 - val_my_iou_metric_2: 0.8095\n",
      "\n",
      "Epoch 00023: val_my_iou_metric_2 did not improve from 0.81950\n",
      "Epoch 24/75\n",
      "7600/7600 [==============================] - 1216s 160ms/step - loss: 0.3010 - my_iou_metric_2: 0.8193 - val_loss: 0.2961 - val_my_iou_metric_2: 0.8255\n",
      "\n",
      "Epoch 00024: val_my_iou_metric_2 improved from 0.81950 to 0.82550, saving model to Unet_resnet_version_11.model\n",
      "Epoch 25/75\n",
      "7600/7600 [==============================] - 1215s 160ms/step - loss: 0.2987 - my_iou_metric_2: 0.8209 - val_loss: 0.3298 - val_my_iou_metric_2: 0.8185\n",
      "\n",
      "Epoch 00025: val_my_iou_metric_2 did not improve from 0.82550\n",
      "Epoch 26/75\n",
      "7600/7600 [==============================] - 1215s 160ms/step - loss: 0.3003 - my_iou_metric_2: 0.8174 - val_loss: 0.3565 - val_my_iou_metric_2: 0.8010\n",
      "\n",
      "Epoch 00026: val_my_iou_metric_2 did not improve from 0.82550\n",
      "Epoch 27/75\n",
      "7600/7600 [==============================] - 1214s 160ms/step - loss: 0.3206 - my_iou_metric_2: 0.8097 - val_loss: 0.3086 - val_my_iou_metric_2: 0.8170\n",
      "\n",
      "Epoch 00027: val_my_iou_metric_2 did not improve from 0.82550\n",
      "Epoch 28/75\n",
      "7600/7600 [==============================] - 1213s 160ms/step - loss: 0.3005 - my_iou_metric_2: 0.8198 - val_loss: 0.3322 - val_my_iou_metric_2: 0.8220\n",
      "\n",
      "Epoch 00028: val_my_iou_metric_2 did not improve from 0.82550\n",
      "Epoch 29/75\n",
      "7600/7600 [==============================] - 1213s 160ms/step - loss: 0.3072 - my_iou_metric_2: 0.8157 - val_loss: 0.3285 - val_my_iou_metric_2: 0.8185\n",
      "\n",
      "Epoch 00029: val_my_iou_metric_2 did not improve from 0.82550\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 30/75\n",
      "7600/7600 [==============================] - 1213s 160ms/step - loss: 0.2808 - my_iou_metric_2: 0.8304 - val_loss: 0.3241 - val_my_iou_metric_2: 0.8105\n",
      "\n",
      "Epoch 00030: val_my_iou_metric_2 did not improve from 0.82550\n",
      "Epoch 31/75\n",
      "7600/7600 [==============================] - 1213s 160ms/step - loss: 0.2864 - my_iou_metric_2: 0.8265 - val_loss: 0.3034 - val_my_iou_metric_2: 0.8320\n",
      "\n",
      "Epoch 00031: val_my_iou_metric_2 improved from 0.82550 to 0.83200, saving model to Unet_resnet_version_11.model\n",
      "Epoch 32/75\n",
      "7600/7600 [==============================] - 1214s 160ms/step - loss: 0.2826 - my_iou_metric_2: 0.8279 - val_loss: 0.3017 - val_my_iou_metric_2: 0.8245\n",
      "\n",
      "Epoch 00032: val_my_iou_metric_2 did not improve from 0.83200\n",
      "Epoch 33/75\n",
      "7600/7600 [==============================] - 1220s 161ms/step - loss: 0.2728 - my_iou_metric_2: 0.8334 - val_loss: 0.3092 - val_my_iou_metric_2: 0.8230\n",
      "\n",
      "Epoch 00033: val_my_iou_metric_2 did not improve from 0.83200\n",
      "Epoch 34/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7600/7600 [==============================] - 1222s 161ms/step - loss: 0.2765 - my_iou_metric_2: 0.8326 - val_loss: 0.3059 - val_my_iou_metric_2: 0.8290\n",
      "\n",
      "Epoch 00034: val_my_iou_metric_2 did not improve from 0.83200\n",
      "Epoch 35/75\n",
      "7600/7600 [==============================] - 1225s 161ms/step - loss: 0.2701 - my_iou_metric_2: 0.8344 - val_loss: 0.3239 - val_my_iou_metric_2: 0.8175\n",
      "\n",
      "Epoch 00035: val_my_iou_metric_2 did not improve from 0.83200\n",
      "Epoch 36/75\n",
      "7600/7600 [==============================] - 1228s 162ms/step - loss: 0.2838 - my_iou_metric_2: 0.8284 - val_loss: 0.3117 - val_my_iou_metric_2: 0.8210\n",
      "\n",
      "Epoch 00036: val_my_iou_metric_2 did not improve from 0.83200\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 37/75\n",
      "7600/7600 [==============================] - 1228s 162ms/step - loss: 0.2667 - my_iou_metric_2: 0.8361 - val_loss: 0.2947 - val_my_iou_metric_2: 0.8300\n",
      "\n",
      "Epoch 00037: val_my_iou_metric_2 did not improve from 0.83200\n",
      "Epoch 38/75\n",
      "7600/7600 [==============================] - 1249s 164ms/step - loss: 0.2627 - my_iou_metric_2: 0.8390 - val_loss: 0.3034 - val_my_iou_metric_2: 0.8250\n",
      "\n",
      "Epoch 00038: val_my_iou_metric_2 did not improve from 0.83200\n",
      "Epoch 39/75\n",
      "7600/7600 [==============================] - 1311s 172ms/step - loss: 0.2598 - my_iou_metric_2: 0.8396 - val_loss: 0.2981 - val_my_iou_metric_2: 0.8300\n",
      "\n",
      "Epoch 00039: val_my_iou_metric_2 did not improve from 0.83200\n",
      "Epoch 40/75\n",
      "7600/7600 [==============================] - 1307s 172ms/step - loss: 0.2603 - my_iou_metric_2: 0.8400 - val_loss: 0.2953 - val_my_iou_metric_2: 0.8305\n",
      "\n",
      "Epoch 00040: val_my_iou_metric_2 did not improve from 0.83200\n",
      "Epoch 41/75\n",
      "7600/7600 [==============================] - 1313s 173ms/step - loss: 0.2598 - my_iou_metric_2: 0.8396 - val_loss: 0.3068 - val_my_iou_metric_2: 0.8250\n",
      "\n",
      "Epoch 00041: val_my_iou_metric_2 did not improve from 0.83200\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 42/75\n",
      "7600/7600 [==============================] - 1341s 176ms/step - loss: 0.2538 - my_iou_metric_2: 0.8443 - val_loss: 0.3054 - val_my_iou_metric_2: 0.8215\n",
      "\n",
      "Epoch 00042: val_my_iou_metric_2 did not improve from 0.83200\n",
      "Epoch 43/75\n",
      "7600/7600 [==============================] - 1325s 174ms/step - loss: 0.2505 - my_iou_metric_2: 0.8451 - val_loss: 0.3077 - val_my_iou_metric_2: 0.8225\n",
      "\n",
      "Epoch 00043: val_my_iou_metric_2 did not improve from 0.83200\n",
      "Epoch 44/75\n",
      "7600/7600 [==============================] - 1292s 170ms/step - loss: 0.2509 - my_iou_metric_2: 0.8456 - val_loss: 0.2971 - val_my_iou_metric_2: 0.8285\n",
      "\n",
      "Epoch 00044: val_my_iou_metric_2 did not improve from 0.83200\n",
      "Epoch 45/75\n",
      "7600/7600 [==============================] - 1278s 168ms/step - loss: 0.2529 - my_iou_metric_2: 0.8437 - val_loss: 0.3023 - val_my_iou_metric_2: 0.8270\n",
      "\n",
      "Epoch 00045: val_my_iou_metric_2 did not improve from 0.83200\n",
      "Epoch 46/75\n",
      "7600/7600 [==============================] - 1295s 170ms/step - loss: 0.2466 - my_iou_metric_2: 0.8468 - val_loss: 0.2865 - val_my_iou_metric_2: 0.8360\n",
      "\n",
      "Epoch 00046: val_my_iou_metric_2 improved from 0.83200 to 0.83600, saving model to Unet_resnet_version_11.model\n",
      "Epoch 47/75\n",
      "7600/7600 [==============================] - 1317s 173ms/step - loss: 0.2516 - my_iou_metric_2: 0.8443 - val_loss: 0.2900 - val_my_iou_metric_2: 0.8350\n",
      "\n",
      "Epoch 00047: val_my_iou_metric_2 did not improve from 0.83600\n",
      "Epoch 48/75\n",
      "7600/7600 [==============================] - 1347s 177ms/step - loss: 0.2467 - my_iou_metric_2: 0.8480 - val_loss: 0.2932 - val_my_iou_metric_2: 0.8295\n",
      "\n",
      "Epoch 00048: val_my_iou_metric_2 did not improve from 0.83600\n",
      "Epoch 49/75\n",
      "7600/7600 [==============================] - 1308s 172ms/step - loss: 0.2458 - my_iou_metric_2: 0.8478 - val_loss: 0.2808 - val_my_iou_metric_2: 0.8370\n",
      "\n",
      "Epoch 00049: val_my_iou_metric_2 improved from 0.83600 to 0.83700, saving model to Unet_resnet_version_11.model\n",
      "Epoch 50/75\n",
      "7600/7600 [==============================] - 1253s 165ms/step - loss: 0.2444 - my_iou_metric_2: 0.8499 - val_loss: 0.2941 - val_my_iou_metric_2: 0.8345\n",
      "\n",
      "Epoch 00050: val_my_iou_metric_2 did not improve from 0.83700\n",
      "Epoch 51/75\n",
      "7600/7600 [==============================] - 1256s 165ms/step - loss: 0.2458 - my_iou_metric_2: 0.8487 - val_loss: 0.3009 - val_my_iou_metric_2: 0.8295\n",
      "\n",
      "Epoch 00051: val_my_iou_metric_2 did not improve from 0.83700\n",
      "Epoch 52/75\n",
      "7600/7600 [==============================] - 1240s 163ms/step - loss: 0.2536 - my_iou_metric_2: 0.8436 - val_loss: 0.2860 - val_my_iou_metric_2: 0.8305\n",
      "\n",
      "Epoch 00052: val_my_iou_metric_2 did not improve from 0.83700\n",
      "Epoch 53/75\n",
      "7600/7600 [==============================] - 1200s 158ms/step - loss: 0.2445 - my_iou_metric_2: 0.8474 - val_loss: 0.3071 - val_my_iou_metric_2: 0.8225\n",
      "\n",
      "Epoch 00053: val_my_iou_metric_2 did not improve from 0.83700\n",
      "Epoch 54/75\n",
      "7600/7600 [==============================] - 1214s 160ms/step - loss: 0.2463 - my_iou_metric_2: 0.8465 - val_loss: 0.3073 - val_my_iou_metric_2: 0.8205\n",
      "\n",
      "Epoch 00054: val_my_iou_metric_2 did not improve from 0.83700\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 55/75\n",
      "7600/7600 [==============================] - 1199s 158ms/step - loss: 0.2434 - my_iou_metric_2: 0.8486 - val_loss: 0.3059 - val_my_iou_metric_2: 0.8230\n",
      "\n",
      "Epoch 00055: val_my_iou_metric_2 did not improve from 0.83700\n",
      "Epoch 56/75\n",
      "7600/7600 [==============================] - 1239s 163ms/step - loss: 0.2404 - my_iou_metric_2: 0.8505 - val_loss: 0.2934 - val_my_iou_metric_2: 0.8340\n",
      "\n",
      "Epoch 00056: val_my_iou_metric_2 did not improve from 0.83700\n",
      "Epoch 57/75\n",
      "7600/7600 [==============================] - 1235s 163ms/step - loss: 0.2413 - my_iou_metric_2: 0.8503 - val_loss: 0.2786 - val_my_iou_metric_2: 0.8390\n",
      "\n",
      "Epoch 00057: val_my_iou_metric_2 improved from 0.83700 to 0.83900, saving model to Unet_resnet_version_11.model\n",
      "Epoch 58/75\n",
      "7600/7600 [==============================] - 1242s 163ms/step - loss: 0.2415 - my_iou_metric_2: 0.8502 - val_loss: 0.2927 - val_my_iou_metric_2: 0.8330\n",
      "\n",
      "Epoch 00058: val_my_iou_metric_2 did not improve from 0.83900\n",
      "Epoch 59/75\n",
      "7600/7600 [==============================] - 1224s 161ms/step - loss: 0.2429 - my_iou_metric_2: 0.8484 - val_loss: 0.2801 - val_my_iou_metric_2: 0.8410\n",
      "\n",
      "Epoch 00059: val_my_iou_metric_2 improved from 0.83900 to 0.84100, saving model to Unet_resnet_version_11.model\n",
      "Epoch 60/75\n",
      "7600/7600 [==============================] - 1234s 162ms/step - loss: 0.2426 - my_iou_metric_2: 0.8493 - val_loss: 0.2912 - val_my_iou_metric_2: 0.8300\n",
      "\n",
      "Epoch 00060: val_my_iou_metric_2 did not improve from 0.84100\n",
      "Epoch 61/75\n",
      "7600/7600 [==============================] - 1223s 161ms/step - loss: 0.2425 - my_iou_metric_2: 0.8502 - val_loss: 0.2892 - val_my_iou_metric_2: 0.8365\n",
      "\n",
      "Epoch 00061: val_my_iou_metric_2 did not improve from 0.84100\n",
      "Epoch 62/75\n",
      "7600/7600 [==============================] - 1273s 168ms/step - loss: 0.2385 - my_iou_metric_2: 0.8516 - val_loss: 0.2863 - val_my_iou_metric_2: 0.8360\n",
      "\n",
      "Epoch 00062: val_my_iou_metric_2 did not improve from 0.84100\n",
      "Epoch 63/75\n",
      "7600/7600 [==============================] - 1303s 171ms/step - loss: 0.2424 - my_iou_metric_2: 0.8504 - val_loss: 0.2866 - val_my_iou_metric_2: 0.8350\n",
      "\n",
      "Epoch 00063: val_my_iou_metric_2 did not improve from 0.84100\n",
      "Epoch 64/75\n",
      "7600/7600 [==============================] - 1324s 174ms/step - loss: 0.2398 - my_iou_metric_2: 0.8512 - val_loss: 0.2745 - val_my_iou_metric_2: 0.8405\n",
      "\n",
      "Epoch 00064: val_my_iou_metric_2 did not improve from 0.84100\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Epoch 65/75\n",
      "7600/7600 [==============================] - 1312s 173ms/step - loss: 0.2429 - my_iou_metric_2: 0.8497 - val_loss: 0.2820 - val_my_iou_metric_2: 0.8350\n",
      "\n",
      "Epoch 00065: val_my_iou_metric_2 did not improve from 0.84100\n",
      "Epoch 66/75\n",
      "7600/7600 [==============================] - 1301s 171ms/step - loss: 0.2398 - my_iou_metric_2: 0.8495 - val_loss: 0.2815 - val_my_iou_metric_2: 0.8360\n",
      "\n",
      "Epoch 00066: val_my_iou_metric_2 did not improve from 0.84100\n",
      "Epoch 67/75\n",
      "7600/7600 [==============================] - 1311s 172ms/step - loss: 0.2390 - my_iou_metric_2: 0.8522 - val_loss: 0.2928 - val_my_iou_metric_2: 0.8330\n",
      "\n",
      "Epoch 00067: val_my_iou_metric_2 did not improve from 0.84100\n",
      "Epoch 68/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7600/7600 [==============================] - 1309s 172ms/step - loss: 0.2374 - my_iou_metric_2: 0.8515 - val_loss: 0.2801 - val_my_iou_metric_2: 0.8365\n",
      "\n",
      "Epoch 00068: val_my_iou_metric_2 did not improve from 0.84100\n",
      "Epoch 69/75\n",
      "7600/7600 [==============================] - 1301s 171ms/step - loss: 0.2389 - my_iou_metric_2: 0.8515 - val_loss: 0.2911 - val_my_iou_metric_2: 0.8335\n",
      "\n",
      "Epoch 00069: val_my_iou_metric_2 did not improve from 0.84100\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 70/75\n",
      "7600/7600 [==============================] - 1289s 170ms/step - loss: 0.2367 - my_iou_metric_2: 0.8524 - val_loss: 0.2902 - val_my_iou_metric_2: 0.8330\n",
      "\n",
      "Epoch 00070: val_my_iou_metric_2 did not improve from 0.84100\n",
      "Epoch 71/75\n",
      "7600/7600 [==============================] - 1294s 170ms/step - loss: 0.2378 - my_iou_metric_2: 0.8524 - val_loss: 0.2896 - val_my_iou_metric_2: 0.8340\n",
      "\n",
      "Epoch 00071: val_my_iou_metric_2 did not improve from 0.84100\n",
      "Epoch 72/75\n",
      "7600/7600 [==============================] - 1288s 169ms/step - loss: 0.2374 - my_iou_metric_2: 0.8522 - val_loss: 0.2897 - val_my_iou_metric_2: 0.8340\n",
      "\n",
      "Epoch 00072: val_my_iou_metric_2 did not improve from 0.84100\n",
      "Epoch 73/75\n",
      "7600/7600 [==============================] - 1277s 168ms/step - loss: 0.2387 - my_iou_metric_2: 0.8520 - val_loss: 0.2784 - val_my_iou_metric_2: 0.8390\n",
      "\n",
      "Epoch 00073: val_my_iou_metric_2 did not improve from 0.84100\n",
      "Epoch 74/75\n",
      "7600/7600 [==============================] - 1267s 167ms/step - loss: 0.2377 - my_iou_metric_2: 0.8529 - val_loss: 0.2791 - val_my_iou_metric_2: 0.8375\n",
      "\n",
      "Epoch 00074: val_my_iou_metric_2 did not improve from 0.84100\n",
      "Epoch 75/75\n",
      "7600/7600 [==============================] - 1271s 167ms/step - loss: 0.2368 - my_iou_metric_2: 0.8529 - val_loss: 0.2791 - val_my_iou_metric_2: 0.8375\n",
      "\n",
      "Epoch 00075: val_my_iou_metric_2 did not improve from 0.84100\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=20, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric_2', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr,early_stopping], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n",
    "                                                   'lovasz_loss': lovasz_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_result(model,x_test,img_size_target): \n",
    "    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n",
    "    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test += np.array([ np.fliplr(x) for x in preds_test2_refect] )\n",
    "    return preds_test/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,x_valid,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score the model and do a threshold optimization by the best IoU.\n",
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "\n",
    "\n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n",
    "    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n",
    "    intersection = temp1[0]\n",
    "    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n",
    "    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "  \n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    intersection[intersection == 0] = 1e-9\n",
    "    \n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88581657419f46cb977601631c7ff853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.8305 0.8305 0.833  0.832  0.837  0.8375 0.838  0.8385 0.8385 0.839\n",
      " 0.8385 0.839  0.839  0.84   0.846  0.845  0.8435 0.8435 0.8425 0.842\n",
      " 0.841  0.841  0.84   0.8395 0.8395 0.84   0.8395 0.8375 0.837  0.8355\n",
      " 0.8355]\n"
     ]
    }
   ],
   "source": [
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
    "\n",
    "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "print(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a84bdb630>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# instead of using default 0 as threshold, use validation data to find the best threshold.\n",
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "used for converting the decoded image to rle mask\n",
    "Fast compared to previous one\n",
    "\"\"\"\n",
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9b537640084333ba13bbfb6414135a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array([(np.array(load_img(\"competition_data/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a76355bb2d4a4094cc310016bd0e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usedtime = 4.246540784835815 s\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"Usedtime = {t2-t1} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel run time = 53.5721151255899 hours\n"
     ]
    }
   ],
   "source": [
    "t_finish = time.time()\n",
    "print(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
